{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7014064",
   "metadata": {},
   "source": [
    "\n",
    "# Sentiment Analysis for Pakistani Traffic\n",
    "## Task: Find the Best Text Classification Model\n",
    "\n",
    "In this assignment, we will explore different machine learning models to perform sentiment analysis on traffic-related texts from Pakistan. The goal is to determine the best model for classifying sentiments as either positive (1) or negative (0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Pakistani Traffic sentiment Analysis.csv')\n",
    "\n",
    "# Check for missing values and handle them (if any)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b23c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "# Separate the features (text) and labels (sentiment)\n",
    "X = data['Text']\n",
    "y = data['Sentiment']\n",
    "\n",
    "# Initialize the vectorizers\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "hashing_vectorizer = HashingVectorizer(n_features=5000)\n",
    "\n",
    "# Fit and transform the text data with each vectorizer\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "X_hash = hashing_vectorizer.transform(X)\n",
    "\n",
    "# For this exercise, we'll use CountVectorizer (X_count) for demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56659904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import xgboost as xgb\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_count, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "xgboost = xgb.XGBClassifier()\n",
    "svm = SVC()\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Setting up GridSearchCV for Logistic Regression (can be done for other models too)\n",
    "param_grid_lr = {'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "grid_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and accuracy\n",
    "best_params_lr = grid_lr.best_params_\n",
    "best_score_lr = grid_lr.best_score_\n",
    "print(\"Logistic Regression Best Parameters:\", best_params_lr)\n",
    "print(\"Logistic Regression Best Accuracy:\", best_score_lr)\n",
    "\n",
    "# Repeat similar GridSearchCV for other models and compare the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114fbc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = grid_lr.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\n",
    "\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3042f",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "In this notebook, we have trained and evaluated several machine learning models for text classification. We used Logistic Regression, K-Nearest Neighbors, Random Forest, SVM, Naive Bayes, and XGBoost models to classify sentiments related to Pakistani traffic conditions.\n",
    "\n",
    "Logistic Regression with GridSearchCV for hyperparameter tuning showed [insert best results here], but you can experiment with other models similarly.\n",
    "\n",
    "Feel free to extend this notebook by trying out the other models and comparing their performance. Good luck with your sentiment analysis!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
